{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tap-o-chek/Multiple-processing-course/blob/main/labs/MP_Lesson_8_%D0%96%D0%B8%D0%B4%D0%B5%D0%BB%D0%B5%D0%B2%D0%B0_%D0%A1%D0%BE%D1%84%D0%B8%D1%8F.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2JZt1GL5D6W"
      },
      "source": [
        "# Introduction to CUDA and PyCUDA"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```python\n",
        "!pip install pycuda # install cuda\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "import numpy\n",
        "numpy.random.seed(1729)\n",
        "a = numpy.random.randn(4,4)\n",
        "\n",
        "a = a.astype(numpy.float32)\n",
        "a_gpu = cuda.mem_alloc(a.nbytes)\n",
        "cuda.memcpy_htod(a_gpu, a)\n",
        "mod = SourceModule(\"\"\"\n",
        "  __global__ void doublify(float *a)\n",
        "  {\n",
        "    int idx = threadIdx.x + threadIdx.y*4;\n",
        "    a[idx] *= 2;\n",
        "  }\n",
        "  \"\"\")\n",
        "func = mod.get_function(\"doublify\")\n",
        "func(a_gpu, block=(4,4,1))\n",
        "a_doubled = numpy.empty_like(a)\n",
        "cuda.memcpy_dtoh(a_doubled, a_gpu)\n",
        "print(a_doubled)\n",
        "print(a)\n",
        "b = numpy.random.randn(4,4)\n",
        "b = b.astype(numpy.float32)\n",
        "c = numpy.random.randn(4,4)\n",
        "c = c.astype(numpy.float32)\n",
        "mod2 = SourceModule(\"\"\"\n",
        "  __global__ void add2(float *a, float *b)\n",
        "  {\n",
        "    int idx = threadIdx.x + threadIdx.y*4;\n",
        "    a[idx] += b[idx];\n",
        "  }\n",
        "  \"\"\")\n",
        "\n",
        "b_gpu = cuda.mem_alloc(b.nbytes)\n",
        "c_gpu = cuda.mem_alloc(c.nbytes)\n",
        "\n",
        "cuda.memcpy_htod(b_gpu, b)\n",
        "cuda.memcpy_htod(c_gpu, c)\n",
        "\n",
        "func = mod2.get_function(\"add2\")\n",
        "func(b_gpu,c_gpu, block=(4,4,1))\n",
        "\n",
        "added = numpy.empty_like(b)\n",
        "cuda.memcpy_dtoh(added, b_gpu)\n",
        "print(added)\n",
        "print(b)\n",
        "print(c)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "caFT5HQjEicT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FA_YN7HlGRP5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9aca8bb-4c02-4043-8795-e56ecf0aded8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycuda\n",
            "  Downloading pycuda-2024.1.tar.gz (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2024.1.1-py2.py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.1/85.1 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from pycuda) (1.4.4)\n",
            "Collecting mako (from pycuda)\n",
            "  Downloading Mako-1.3.3-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.11.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->pycuda) (2.1.5)\n",
            "Building wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2024.1-cp310-cp310-linux_x86_64.whl size=661204 sha256=7205e1929f6a0cbc31c75944e1e6c9282864df504e49bb3c26ee1cd243e6a90d\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/34/d2/9a349255a4eca3a486d82c79d21e138ce2ccd90f414d9d72b8\n",
            "Successfully built pycuda\n",
            "Installing collected packages: pytools, mako, pycuda\n",
            "Successfully installed mako-1.3.3 pycuda-2024.1 pytools-2024.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pycuda # install cuda\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-g92eSBn5FlC"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "numpy.random.seed(1729)\n",
        "a = numpy.random.randn(4,4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Bqm9uTBzJf9X"
      },
      "outputs": [],
      "source": [
        "a = a.astype(numpy.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "92L9E7WkJhsy"
      },
      "outputs": [],
      "source": [
        "a_gpu = cuda.mem_alloc(a.nbytes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "b1xaAt_NJjSb"
      },
      "outputs": [],
      "source": [
        "cuda.memcpy_htod(a_gpu, a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bSAkS6e2Jk38"
      },
      "outputs": [],
      "source": [
        "mod = SourceModule(\"\"\"\n",
        "  __global__ void doublify(float *a)\n",
        "  {\n",
        "    int idx = threadIdx.x + threadIdx.y*4;\n",
        "    a[idx] *= 2;\n",
        "  }\n",
        "  \"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fBQ0blkNJnIg"
      },
      "outputs": [],
      "source": [
        "func = mod.get_function(\"doublify\")\n",
        "func(a_gpu, block=(4,4,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_ef82NDPJqWV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbdcb45f-de7a-4b37-e323-d9d86fed39f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.3746789  -1.6419895   3.3047218  -1.1505861 ]\n",
            " [ 2.1979356   1.8518921  -1.9868276  -1.7164422 ]\n",
            " [ 0.14977352  1.058711    0.2419031  -0.44884723]\n",
            " [-3.113357    0.11188176  0.32294306 -4.2692833 ]]\n",
            "[[-0.6873394  -0.82099473  1.6523609  -0.57529306]\n",
            " [ 1.0989678   0.92594606 -0.9934138  -0.8582211 ]\n",
            " [ 0.07488676  0.5293555   0.12095155 -0.22442362]\n",
            " [-1.5566785   0.05594088  0.16147153 -2.1346416 ]]\n"
          ]
        }
      ],
      "source": [
        "a_doubled = numpy.empty_like(a)\n",
        "cuda.memcpy_dtoh(a_doubled, a_gpu)\n",
        "print(a_doubled)\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "kXx_p97mJs4Z"
      },
      "outputs": [],
      "source": [
        "b = numpy.random.randn(4,4)\n",
        "b = b.astype(numpy.float32)\n",
        "c = numpy.random.randn(4,4)\n",
        "c = c.astype(numpy.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cQYD348qKgva"
      },
      "outputs": [],
      "source": [
        "mod2 = SourceModule(\"\"\"\n",
        "  __global__ void add2(float *a, float *b)\n",
        "  {\n",
        "    int idx = threadIdx.x + threadIdx.y*4;\n",
        "    a[idx] += b[idx];\n",
        "  }\n",
        "  \"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Vs_5Hb-6Kr-C"
      },
      "outputs": [],
      "source": [
        "b_gpu = cuda.mem_alloc(b.nbytes)\n",
        "c_gpu = cuda.mem_alloc(c.nbytes)\n",
        "\n",
        "cuda.memcpy_htod(b_gpu, b)\n",
        "cuda.memcpy_htod(c_gpu, c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WwA4tpOtLE5_"
      },
      "outputs": [],
      "source": [
        "func = mod2.get_function(\"add2\")\n",
        "func(b_gpu,c_gpu, block=(4,4,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0zN8iBYDM_00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff9f5d73-c491-4232-abd5-d356bf985fce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.5257741   0.447586    1.5295702   0.39143866]\n",
            " [ 3.3902154  -2.549993   -1.6982892  -0.2884755 ]\n",
            " [-1.2885619  -1.2470585  -1.3161025   1.1179583 ]\n",
            " [-2.862448   -0.38533747 -0.0221602  -0.24921691]]\n",
            "[[ 0.10967004  0.44301215  0.39626622  0.2497974 ]\n",
            " [ 1.2984973  -1.2804337  -0.97546583 -0.26908663]\n",
            " [-1.1057384  -0.1279927  -0.61782736 -0.98912627]\n",
            " [-2.8598924  -0.7943475  -0.30579695  1.7006376 ]]\n",
            "[[-0.63544416  0.00457387  1.133304    0.14164127]\n",
            " [ 2.091718   -1.2695593  -0.7228234  -0.01938889]\n",
            " [-0.18282357 -1.1190658  -0.6982751   2.1070845 ]\n",
            " [-0.0025556   0.40901005  0.28363675 -1.9498545 ]]\n"
          ]
        }
      ],
      "source": [
        "added = numpy.empty_like(b)\n",
        "cuda.memcpy_dtoh(added, b_gpu)\n",
        "print(added)\n",
        "print(b)\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJBVoR8ANgx5"
      },
      "source": [
        "# Exercises\n",
        "\n",
        "1. Write a cuda kernel to find the elementwise square of a matrix\n",
        "2. Write a cuda kernel to find a matrix, which when added to the given matrix results in every element being equal to zero\n",
        "3. Write a cuda kernel to multiply two matrices:\n",
        "    1. Assume square matrices, with dimensions < 1024\n",
        "    2. Assume square matrices, with dimensions > 1024\n",
        "    3. Assume non-square matrices, with dimensions > 1024"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1\n",
        "Write a cuda kernel to find the elementwise square of a matrix"
      ],
      "metadata": {
        "id": "MO7RFJH9jvaz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numpy.random.seed(1729)\n",
        "matrix = numpy.random.randn(4, 4)\n",
        "matrix = matrix.astype(numpy.float32)\n",
        "\n",
        "matrix_gpu = cuda.mem_alloc(matrix.nbytes)\n",
        "cuda.memcpy_htod(matrix_gpu, matrix)\n",
        "\n",
        "# CUDA-ядро нахождения квадрата элементов матрицы\n",
        "mod_square = SourceModule(\"\"\"\n",
        "__global__ void square_matrix(float *matrix)\n",
        "{\n",
        "    int idx_x = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    int idx_y = threadIdx.y + blockIdx.y * blockDim.y;\n",
        "    int idx = idx_y * blockDim.x * gridDim.x + idx_x;\n",
        "\n",
        "    matrix[idx] = matrix[idx] * matrix[idx];\n",
        "}\n",
        "\"\"\")\n",
        "\n",
        "square_func = mod_square.get_function(\"square_matrix\")\n",
        "\n",
        "block_size = (4, 4, 1)\n",
        "grid_size = (1, 1)\n",
        "square_func(matrix_gpu, block=block_size, grid=grid_size)\n",
        "\n",
        "result = numpy.empty_like(matrix)\n",
        "cuda.memcpy_dtoh(result, matrix_gpu)\n",
        "\n",
        "print(\"Original matrix:\")\n",
        "print(matrix)\n",
        "print(\"\\nSquared matrix:\")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSl4vRkropeB",
        "outputId": "a3edded1-71e1-4f11-ebb8-d7f9055ba119"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original matrix:\n",
            "[[-0.6873394  -0.82099473  1.6523609  -0.57529306]\n",
            " [ 1.0989678   0.92594606 -0.9934138  -0.8582211 ]\n",
            " [ 0.07488676  0.5293555   0.12095155 -0.22442362]\n",
            " [-1.5566785   0.05594088  0.16147153 -2.1346416 ]]\n",
            "\n",
            "Squared matrix:\n",
            "[[4.7243547e-01 6.7403233e-01 2.7302966e+00 3.3096212e-01]\n",
            " [1.2077302e+00 8.5737610e-01 9.8687100e-01 7.3654348e-01]\n",
            " [5.6080269e-03 2.8021726e-01 1.4629277e-02 5.0365958e-02]\n",
            " [2.4232481e+00 3.1293817e-03 2.6073055e-02 4.5566950e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2\n",
        "Write a cuda kernel to find a matrix, which when added to the given matrix results in every element being equal to zero"
      ],
      "metadata": {
        "id": "TPF5QbPhj0yz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# рандомная матрица\n",
        "numpy.random.seed(1729)\n",
        "matrix = numpy.random.randn(4, 4)\n",
        "matrix = matrix.astype(numpy.float32)\n",
        "\n",
        "# Выделяем память на GPU и копируем матрицу на GPU\n",
        "matrix_gpu = cuda.mem_alloc(matrix.nbytes)\n",
        "cuda.memcpy_htod(matrix_gpu, matrix)\n",
        "\n",
        "# CUDA-ядро для нахождения такой матрицы\n",
        "mod_zero = SourceModule(\"\"\"\n",
        "__global__ void find_zero_matrix(float *matrix)\n",
        "{\n",
        "    int idx_x = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    int idx_y = threadIdx.y + blockIdx.y * blockDim.y;\n",
        "    int idx = idx_y * blockDim.x * gridDim.x + idx_x;\n",
        "\n",
        "    matrix[idx] = -matrix[idx]; // Просто инвертируем каждый элемент\n",
        "}\n",
        "\"\"\")\n",
        "\n",
        "zero_func = mod_zero.get_function(\"find_zero_matrix\")  # функция кернела\n",
        "\n",
        "# кернел делаем размером блока (4, 4, 1) и сетку размером (1, 1)\n",
        "block_size = (4, 4, 1)\n",
        "grid_size = (1, 1)\n",
        "zero_func(matrix_gpu, block=block_size, grid=grid_size)\n",
        "\n",
        "# копируем результат обратно на хост\n",
        "result = numpy.empty_like(matrix)\n",
        "cuda.memcpy_dtoh(result, matrix_gpu)\n",
        "\n",
        "print(\"Original matrix:\")\n",
        "print(matrix)\n",
        "print(\"\\nMatrix to add to get zero matrix:\")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvfTT2Zej5v_",
        "outputId": "8a10eb5a-af25-454d-e888-680b63b15546"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/google/colab/_variable_inspector.py:27: UserWarning: device_allocation in out-of-thread context could not be cleaned up\n",
            "  globals().clear()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original matrix:\n",
            "[[-0.6873394  -0.82099473  1.6523609  -0.57529306]\n",
            " [ 1.0989678   0.92594606 -0.9934138  -0.8582211 ]\n",
            " [ 0.07488676  0.5293555   0.12095155 -0.22442362]\n",
            " [-1.5566785   0.05594088  0.16147153 -2.1346416 ]]\n",
            "\n",
            "Matrix to add to get zero matrix:\n",
            "[[ 0.6873394   0.82099473 -1.6523609   0.57529306]\n",
            " [-1.0989678  -0.92594606  0.9934138   0.8582211 ]\n",
            " [-0.07488676 -0.5293555  -0.12095155  0.22442362]\n",
            " [ 1.5566785  -0.05594088 -0.16147153  2.1346416 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 3\n",
        "\n",
        "Write a cuda kernel to multiply two matrices:\n",
        "\n",
        "1. Assume square matrices, with dimensions < 1024\n",
        "2. Assume square matrices, with dimensions > 1024\n",
        "3. Assume non-square matrices, with dimensions > 1024"
      ],
      "metadata": {
        "id": "zTlezuMkj30M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume square matrices, with dimensions < 1024\n",
        "\n",
        "def generate_matrix(rows, cols):\n",
        "    return numpy.random.randn(rows, cols).astype(numpy.float32)\n",
        "\n",
        "# CUDA-ядро для умножения двух матриц\n",
        "mod_mult = SourceModule(\"\"\"\n",
        "__global__ void matrix_multiply(float *a, float *b, float *c, int N)\n",
        "{\n",
        "    int idx_x = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    int idx_y = threadIdx.y + blockIdx.y * blockDim.y;\n",
        "\n",
        "    if (idx_x < N && idx_y < N) {\n",
        "        float val = 0.0f;\n",
        "        for (int k = 0; k < N; ++k) {\n",
        "            val += a[idx_y * N + k] * b[k * N + idx_x];\n",
        "        }\n",
        "        c[idx_y * N + idx_x] = val;\n",
        "    }\n",
        "}\n",
        "\"\"\")\n",
        "\n",
        "mult_func = mod_mult.get_function(\"matrix_multiply\")\n",
        "\n",
        "# размер матрицы\n",
        "size_small = 4\n",
        "\n",
        "a_small = generate_matrix(size_small, size_small)\n",
        "b_small = generate_matrix(size_small, size_small)\n",
        "\n",
        "a_small_gpu = cuda.mem_alloc(a_small.nbytes)\n",
        "b_small_gpu = cuda.mem_alloc(b_small.nbytes)\n",
        "\n",
        "cuda.memcpy_htod(a_small_gpu, a_small)\n",
        "cuda.memcpy_htod(b_small_gpu, b_small)\n",
        "\n",
        "c_small_gpu = cuda.mem_alloc(a_small.nbytes)\n",
        "\n",
        "block_size = (2, 2, 1)\n",
        "grid_size = (size_small // block_size[0] + 1, size_small // block_size[1] + 1)\n",
        "mult_func(a_small_gpu, b_small_gpu, c_small_gpu, numpy.int32(size_small), block=block_size, grid=grid_size)\n",
        "\n",
        "c_small_result = numpy.empty_like(a_small)\n",
        "cuda.memcpy_dtoh(c_small_result, c_small_gpu)\n",
        "print(\"Small matrix multiplication result:\")\n",
        "print(c_small_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpGXW5R-j6FF",
        "outputId": "a474de78-c0f4-493b-d0fc-e40afd69bf3a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Small matrix multiplication result:\n",
            "[[ 0.7838821  -0.90320694 -0.40178114  0.35484213]\n",
            " [-3.324403    2.613077    3.0019403  -1.3219621 ]\n",
            " [ 0.5503916   0.44426364 -1.0097607   0.4727013 ]\n",
            " [ 0.20731163  2.0331752  -1.9710609  -4.3500133 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume square matrices, with dimensions > 1024\n",
        "\n",
        "def generate_matrix(rows, cols):\n",
        "    return numpy.random.randn(rows, cols).astype(numpy.float32)\n",
        "\n",
        "# CUDA-ядро для умножения двух матриц\n",
        "mod_mult = SourceModule(\"\"\"\n",
        "__global__ void matrix_multiply(float *a, float *b, float *c, int N)\n",
        "{\n",
        "    int idx_x = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    int idx_y = threadIdx.y + blockIdx.y * blockDim.y;\n",
        "\n",
        "    if (idx_x < N && idx_y < N) {\n",
        "        float val = 0.0f;\n",
        "        for (int k = 0; k < N; ++k) {\n",
        "            val += a[idx_y * N + k] * b[k * N + idx_x];\n",
        "        }\n",
        "        c[idx_y * N + idx_x] = val;\n",
        "    }\n",
        "}\n",
        "\"\"\")\n",
        "\n",
        "mult_func = mod_mult.get_function(\"matrix_multiply\")\n",
        "\n",
        "# размер матриц\n",
        "size_large = 1030\n",
        "\n",
        "a_large = generate_matrix(size_large, size_large)\n",
        "b_large = generate_matrix(size_large, size_large)\n",
        "\n",
        "a_large_gpu = cuda.mem_alloc(a_large.nbytes)\n",
        "b_large_gpu = cuda.mem_alloc(b_large.nbytes)\n",
        "\n",
        "cuda.memcpy_htod(a_large_gpu, a_large)\n",
        "cuda.memcpy_htod(b_large_gpu, b_large)\n",
        "\n",
        "c_large_gpu = cuda.mem_alloc(a_large.nbytes)\n",
        "\n",
        "block_size = (32, 32, 1)\n",
        "grid_size = (size_large // block_size[0] + 1, size_large // block_size[1] + 1)\n",
        "mult_func(a_large_gpu, b_large_gpu, c_large_gpu, numpy.int32(size_large), block=block_size, grid=grid_size)\n",
        "\n",
        "c_large_result = numpy.empty_like(a_large)\n",
        "cuda.memcpy_dtoh(c_large_result, c_large_gpu)\n",
        "print(\"\\nLarge square matrix multiplication result:\")\n",
        "print(c_large_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5u9KLtd5mXI6",
        "outputId": "0589eacf-6c34-49e1-aaa5-69f9a6f06c2c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Large square matrix multiplication result:\n",
            "[[ 19.105267   26.929924   18.521933  ...  46.614548  -52.872543\n",
            "  -21.14205  ]\n",
            " [-15.012323   -0.8235741  35.496998  ...  19.907202   -7.8865356\n",
            "   67.96503  ]\n",
            " [ 17.873846  -32.292686    1.0756705 ... -33.64744    19.813179\n",
            "   46.307983 ]\n",
            " ...\n",
            " [ 37.80699   -10.161602  -37.41534   ... -11.108911   14.936888\n",
            "  -14.925332 ]\n",
            " [-21.287693   22.055311   35.86268   ...  99.76683   -43.925674\n",
            "  -54.055645 ]\n",
            " [ -9.169684   48.606525   43.21028   ... -27.21785    10.442835\n",
            "  -60.03849  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/google/colab/_variable_inspector.py:27: UserWarning: module in out-of-thread context could not be cleaned up\n",
            "  globals().clear()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume non-square matrices, with dimensions > 1024\n",
        "\n",
        "def generate_matrix(rows, cols):\n",
        "    return numpy.random.randn(rows, cols).astype(numpy.float32)\n",
        "\n",
        "# CUDA-ядро для умножения двух матриц\n",
        "mod_mult = SourceModule(\"\"\"\n",
        "__global__ void matrix_multiply(float *a, float *b, float *c, int N)\n",
        "{\n",
        "    int idx_x = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    int idx_y = threadIdx.y + blockIdx.y * blockDim.y;\n",
        "\n",
        "    if (idx_x < N && idx_y < N) {\n",
        "        float val = 0.0f;\n",
        "        for (int k = 0; k < N; ++k) {\n",
        "            val += a[idx_y * N + k] * b[k * N + idx_x];\n",
        "        }\n",
        "        c[idx_y * N + idx_x] = val;\n",
        "    }\n",
        "}\n",
        "\"\"\")\n",
        "\n",
        "mult_func = mod_mult.get_function(\"matrix_multiply\")\n",
        "\n",
        "# задаём размеры матриц\n",
        "size_rows_large = 1050\n",
        "size_cols_large = 1070\n",
        "\n",
        "a_rect = generate_matrix(size_rows_large, size_cols_large)\n",
        "b_rect = generate_matrix(size_cols_large, size_rows_large)\n",
        "\n",
        "a_rect_gpu = cuda.mem_alloc(a_rect.nbytes)\n",
        "b_rect_gpu = cuda.mem_alloc(b_rect.nbytes)\n",
        "\n",
        "cuda.memcpy_htod(a_rect_gpu, a_rect)\n",
        "cuda.memcpy_htod(b_rect_gpu, b_rect)\n",
        "\n",
        "# выделяем память под результат на GPU\n",
        "c_rect_gpu = cuda.mem_alloc(a_rect.nbytes)\n",
        "\n",
        "block_size = (32, 32, 1)\n",
        "grid_size_rect = (size_cols_large // block_size[0] + 1, size_rows_large // block_size[1] + 1)\n",
        "mult_func(a_rect_gpu, b_rect_gpu, c_rect_gpu, numpy.int32(size_cols_large), block=block_size, grid=grid_size_rect)\n",
        "\n",
        "c_rect_result = numpy.empty_like(a_rect)\n",
        "cuda.memcpy_dtoh(c_rect_result, c_rect_gpu)\n",
        "print(\"\\nLarge rectangular matrix multiplication result:\")\n",
        "print(c_rect_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSIJ2WbBmZX-",
        "outputId": "00908937-d3ec-424c-b4b5-45476df27f85"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Large rectangular matrix multiplication result:\n",
            "[[  -6.003228    -8.127362    -5.2243066 ...   -3.6504724   -6.505844\n",
            "   -35.203945 ]\n",
            " [ -21.96266     -2.4735224  -24.543442  ...    3.784975   -44.2885\n",
            "    26.5535   ]\n",
            " [   9.510945    -1.0790826   35.151436  ... -100.9466       9.979017\n",
            "   -35.656456 ]\n",
            " ...\n",
            " [ -37.479874    16.72282    -68.070984  ...  -11.42971     13.359587\n",
            "   -69.39042  ]\n",
            " [  10.844261   -28.928165   -48.18363   ...   38.748394   -12.242909\n",
            "    29.673944 ]\n",
            " [  -3.8384736    0.5997028   17.338821  ...  -23.069664    44.882378\n",
            "   -10.977278 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/google/colab/_variable_inspector.py:27: UserWarning: module in out-of-thread context could not be cleaned up\n",
            "  globals().clear()\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}